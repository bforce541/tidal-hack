#!/usr/bin/env python3
"""
Data Readiness pipeline: load Excel runs, validate schema, produce clean CSV + quality report.

Outputs:
  - all_runs_clean.csv   (concatenated normalized runs)
  - data_quality.csv     (per-run stats: row_count, % missing key columns)
  - schema_report.json   (schema discovery report)
  - README.md            (short summary)

Can be run as CLI or imported and called programmatically.
"""

import argparse
import json
import logging
import sys
from pathlib import Path
from typing import Any

import pandas as pd

from src.schema import (
    CLOCK_POSITION,
    FEATURE_TYPE,
    JOINT_NUMBER,
    load_and_parse_runs,
    write_schema_report,
)
from src.normalize import normalize_all

logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)

ALL_RUNS_CLEAN_CSV = "all_runs_clean.csv"
DATA_QUALITY_CSV = "data_quality.csv"
SCHEMA_REPORT_JSON = "schema_report.json"
README_MD = "README.md"


def _quality_row(df: pd.DataFrame, run_year: int) -> dict[str, Any]:
    """Compute one row of data_quality: row_count and % missing for key columns."""
    n = len(df)
    row: dict[str, Any] = {"run_year": run_year, "row_count": n}
    if n == 0:
        row["pct_missing_joint_number"] = None
        row["pct_missing_clock_position_deg"] = None
        row["pct_missing_feature_type"] = None
        row["pct_missing_depth_percent"] = None
        return row
    for col, key in [
        (JOINT_NUMBER, "pct_missing_joint_number"),
        (CLOCK_POSITION, "pct_missing_clock_position_deg"),
        (FEATURE_TYPE, "pct_missing_feature_type"),
        ("depth_percent", "pct_missing_depth_percent"),
    ]:
        if col in df.columns:
            missing = df[col].isna().sum()
            row[key] = round(100.0 * missing / n, 2)
        else:
            row[key] = 100.0
    return row


def run_data_readiness(
    input_path: str | Path,
    out_dir: str | Path,
    runs: list[int],
    debug: bool = False,
) -> dict[str, Any]:
    """
    Run the data readiness pipeline: load, parse, normalize, write outputs.

    Returns a dict suitable for JSON API response:
      status, out_dir, outputs (paths), summary (key stats).
    """
    input_path = Path(input_path)
    out_dir = Path(out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    if not input_path.exists():
        return {
            "status": "error",
            "error": f"Input path does not exist: {input_path}",
            "out_dir": str(out_dir.resolve()),
            "outputs": {},
            "summary": {},
        }

    try:
        logger.info("Loading and parsing runs %s from %s", runs, input_path)
        parsed, schema_report = load_and_parse_runs(input_path, runs)
        if len(parsed) == 0:
            return {
                "status": "error",
                "error": "No runs could be parsed; check sheet names and run years.",
                "out_dir": str(out_dir.resolve()),
                "outputs": {},
                "summary": {},
            }

        logger.info("Normalizing...")
        normalized = normalize_all(parsed, schema_report)

        # all_runs_clean.csv: concatenate all runs
        combined = pd.concat(normalized.values(), ignore_index=True)
        all_runs_path = out_dir / ALL_RUNS_CLEAN_CSV
        combined.to_csv(all_runs_path, index=False)
        logger.info("Wrote %s (%d rows)", all_runs_path, len(combined))

        # data_quality.csv: per-run stats
        quality_rows = [_quality_row(normalized[yr], yr) for yr in sorted(normalized.keys())]
        quality_df = pd.DataFrame(quality_rows)
        quality_path = out_dir / DATA_QUALITY_CSV
        quality_df.to_csv(quality_path, index=False)
        logger.info("Wrote %s", quality_path)

        # schema_report.json
        schema_path = out_dir / SCHEMA_REPORT_JSON
        write_schema_report(schema_report, schema_path)
        logger.info("Wrote %s", schema_path)

        # README.md
        readme_path = out_dir / README_MD
        summary_lines = [
            "# Data Readiness Output",
            "",
            f"**Source:** `{input_path.name}`",
            f"**Runs:** {runs}",
            "",
            "## Outputs",
            f"- `{ALL_RUNS_CLEAN_CSV}` — {len(combined)} rows (all runs combined)",
            f"- `{DATA_QUALITY_CSV}` — per-run quality metrics",
            f"- `{SCHEMA_REPORT_JSON}` — schema discovery report",
            "",
            "## Per-run row counts",
        ]
        for r in quality_rows:
            summary_lines.append(f"- Run {r['run_year']}: {r['row_count']} rows")
        summary_lines.extend(["", "Generated by run_data_ready.py"])
        readme_path.write_text("\n".join(summary_lines), encoding="utf-8")
        logger.info("Wrote %s", readme_path)

        abs_out = out_dir.resolve()
        summary = {
            "row_count_per_run": {r["run_year"]: r["row_count"] for r in quality_rows},
            "total_rows": int(len(combined)),
            "runs_processed": sorted(normalized.keys()),
        }
        for r in quality_rows:
            yr = r["run_year"]
            if r.get("pct_missing_joint_number") is not None:
                summary[f"pct_missing_joint_number_run_{yr}"] = r["pct_missing_joint_number"]
            if r.get("pct_missing_clock_position_deg") is not None:
                summary[f"pct_missing_clock_position_deg_run_{yr}"] = r["pct_missing_clock_position_deg"]

        return {
            "status": "ok",
            "out_dir": str(abs_out),
            "outputs": {
                "all_runs_clean_csv": str(abs_out / ALL_RUNS_CLEAN_CSV),
                "data_quality_csv": str(abs_out / DATA_QUALITY_CSV),
                "schema_report_json": str(abs_out / SCHEMA_REPORT_JSON),
                "readme_md": str(abs_out / README_MD),
            },
            "summary": summary,
            "data_quality_rows": quality_rows,
        }
    except Exception as e:
        if debug:
            import traceback
            traceback.print_exc()
        return {
            "status": "error",
            "error": str(e),
            "out_dir": str(out_dir.resolve()),
            "outputs": {},
            "summary": {},
        }


def main() -> int:
    parser = argparse.ArgumentParser(
        description="Data Readiness: load Excel runs, produce all_runs_clean.csv, data_quality.csv, schema_report.json, README.md"
    )
    parser.add_argument("--input", "-i", required=True, help="Path to Excel file")
    parser.add_argument("--out-dir", "-o", default="data_ready", help="Output directory (default: data_ready)")
    parser.add_argument("--runs", type=int, nargs="+", required=True, help="Run years, e.g. 2007 2015 2022")
    parser.add_argument("--debug", action="store_true", help="Print traceback on error")
    args = parser.parse_args()

    result = run_data_readiness(
        input_path=args.input,
        out_dir=args.out_dir,
        runs=args.runs,
        debug=args.debug,
    )
    if result["status"] != "ok":
        print(result.get("error", "Unknown error"), file=sys.stderr)
        return 1
    print(json.dumps(result, indent=2))
    return 0


if __name__ == "__main__":
    sys.exit(main())
